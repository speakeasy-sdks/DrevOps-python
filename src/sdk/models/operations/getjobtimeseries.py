"""Code generated by Speakeasy (https://speakeasyapi.dev). DO NOT EDIT."""

from __future__ import annotations
import dataclasses
import dateutil.parser
import requests as requests_http
from dataclasses_json import Undefined, dataclass_json
from datetime import datetime
from enum import Enum
from marshmallow import fields
from sdk import utils
from typing import Optional

class GetJobTimeseriesGranularity(str, Enum):
    r"""The granularity for which to query timeseries data."""
    DAILY = 'daily'
    HOURLY = 'hourly'



@dataclasses.dataclass
class GetJobTimeseriesRequest:
    project_slug: str = dataclasses.field(metadata={'path_param': { 'field_name': 'project-slug', 'style': 'simple', 'explode': False }})
    r"""Project slug in the form `vcs-slug/org-name/repo-name`. The `/` characters may be URL-escaped."""
    workflow_name: str = dataclasses.field(metadata={'path_param': { 'field_name': 'workflow-name', 'style': 'simple', 'explode': False }})
    r"""The name of the workflow."""
    branch: Optional[str] = dataclasses.field(default=None, metadata={'query_param': { 'field_name': 'branch', 'style': 'form', 'explode': True }})
    r"""The name of a vcs branch. If not passed we will scope the API call to the default branch."""
    end_date: Optional[datetime] = dataclasses.field(default=None, metadata={'query_param': { 'field_name': 'end-date', 'style': 'form', 'explode': True }})
    r"""Include only executions that started before this date. This date can be at most 90 days after the start-date."""
    granularity: Optional[GetJobTimeseriesGranularity] = dataclasses.field(default=None, metadata={'query_param': { 'field_name': 'granularity', 'style': 'form', 'explode': True }})
    r"""The granularity for which to query timeseries data."""
    start_date: Optional[datetime] = dataclasses.field(default=None, metadata={'query_param': { 'field_name': 'start-date', 'style': 'form', 'explode': True }})
    r"""Include only executions that started at or after this date. This must be specified if an end-date is provided."""
    



@dataclass_json(undefined=Undefined.EXCLUDE)

@dataclasses.dataclass
class GetJobTimeseriesDefaultApplicationJSON:
    r"""Error response."""
    message: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('message'), 'exclude': lambda f: f is None }})
    



@dataclass_json(undefined=Undefined.EXCLUDE)

@dataclasses.dataclass
class GetJobTimeseries200ApplicationJSONItemsMetricsDurationMetrics:
    r"""Metrics relating to the duration of runs for a workflow."""
    max: int = dataclasses.field(metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('max') }})
    r"""The max duration, in seconds, among a group of runs."""
    median: int = dataclasses.field(metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('median') }})
    r"""The median duration, in seconds, among a group of runs."""
    min: int = dataclasses.field(metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('min') }})
    r"""The minimum duration, in seconds, among a group of runs."""
    p95: int = dataclasses.field(metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('p95') }})
    r"""The 95th percentile duration, in seconds, among a group of runs."""
    total: int = dataclasses.field(metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('total') }})
    r"""The total duration, in seconds, added across a group of runs."""
    



@dataclass_json(undefined=Undefined.EXCLUDE)

@dataclasses.dataclass
class GetJobTimeseries200ApplicationJSONItemsMetrics:
    r"""Metrics relating to a workflow's runs."""
    duration_metrics: GetJobTimeseries200ApplicationJSONItemsMetricsDurationMetrics = dataclasses.field(metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('duration_metrics') }})
    r"""Metrics relating to the duration of runs for a workflow."""
    failed_runs: int = dataclasses.field(metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('failed_runs') }})
    r"""The number of failed runs."""
    median_credits_used: int = dataclasses.field(metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('median_credits_used') }})
    r"""The median credits consumed over the current timeseries interval."""
    successful_runs: int = dataclasses.field(metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('successful_runs') }})
    r"""The number of successful runs."""
    throughput: float = dataclasses.field(metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('throughput') }})
    r"""The average number of runs per day."""
    total_credits_used: int = dataclasses.field(metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('total_credits_used') }})
    r"""The total credits consumed over the current timeseries interval."""
    total_runs: int = dataclasses.field(metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('total_runs') }})
    r"""The total number of runs."""
    



@dataclass_json(undefined=Undefined.EXCLUDE)

@dataclasses.dataclass
class GetJobTimeseries200ApplicationJSONItems:
    max_ended_at: datetime = dataclasses.field(metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('max_ended_at'), 'encoder': utils.datetimeisoformat(False), 'decoder': dateutil.parser.isoparse, 'mm_field': fields.DateTime(format='iso') }})
    r"""The end time of the last execution included in the metrics."""
    metrics: GetJobTimeseries200ApplicationJSONItemsMetrics = dataclasses.field(metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('metrics') }})
    r"""Metrics relating to a workflow's runs."""
    min_started_at: datetime = dataclasses.field(metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('min_started_at'), 'encoder': utils.datetimeisoformat(False), 'decoder': dateutil.parser.isoparse, 'mm_field': fields.DateTime(format='iso') }})
    r"""The start time for the earliest execution included in the metrics."""
    name: str = dataclasses.field(metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('name') }})
    r"""The name of the workflow."""
    timestamp: datetime = dataclasses.field(metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('timestamp'), 'encoder': utils.datetimeisoformat(False), 'decoder': dateutil.parser.isoparse, 'mm_field': fields.DateTime(format='iso') }})
    r"""The start of the interval for timeseries metrics."""
    



@dataclass_json(undefined=Undefined.EXCLUDE)

@dataclasses.dataclass
class GetJobTimeseries200ApplicationJSON:
    r"""Project level timeseries metrics response"""
    items: list[GetJobTimeseries200ApplicationJSONItems] = dataclasses.field(metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('items') }})
    r"""Aggregate metrics for a workflow at a time granularity"""
    next_page_token: str = dataclasses.field(metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('next_page_token') }})
    r"""A token to pass as a `page-token` query parameter to return the next page of results."""
    




@dataclasses.dataclass
class GetJobTimeseriesResponse:
    content_type: str = dataclasses.field()
    status_code: int = dataclasses.field()
    get_job_timeseries_200_application_json_object: Optional[GetJobTimeseries200ApplicationJSON] = dataclasses.field(default=None)
    r"""An array of timeseries data, one entry per job."""
    get_job_timeseries_default_application_json_object: Optional[GetJobTimeseriesDefaultApplicationJSON] = dataclasses.field(default=None)
    r"""Error response."""
    raw_response: Optional[requests_http.Response] = dataclasses.field(default=None)
    

